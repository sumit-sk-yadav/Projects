{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 549982 to 247927\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    10000 non-null  int64  \n",
      " 1   Age                   9850 non-null   float64\n",
      " 2   Gender                10000 non-null  object \n",
      " 3   Annual Income         9607 non-null   float64\n",
      " 4   Marital Status        9838 non-null   object \n",
      " 5   Number of Dependents  9097 non-null   float64\n",
      " 6   Education Level       10000 non-null  object \n",
      " 7   Occupation            7002 non-null   object \n",
      " 8   Health Score          9384 non-null   float64\n",
      " 9   Location              10000 non-null  object \n",
      " 10  Policy Type           10000 non-null  object \n",
      " 11  Previous Claims       6968 non-null   float64\n",
      " 12  Vehicle Age           10000 non-null  float64\n",
      " 13  Credit Score          8874 non-null   float64\n",
      " 14  Insurance Duration    10000 non-null  float64\n",
      " 15  Policy Start Date     10000 non-null  object \n",
      " 16  Customer Feedback     9358 non-null   object \n",
      " 17  Smoking Status        10000 non-null  object \n",
      " 18  Exercise Frequency    10000 non-null  object \n",
      " 19  Property Type         10000 non-null  object \n",
      " 20  Premium Amount        10000 non-null  float64\n",
      "dtypes: float64(9), int64(1), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/IR_raw_data.csv')\n",
    "data = data.sample(10000, random_state=13)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = data.select_dtypes(exclude='object').drop(['Premium Amount','id'], axis = 1).columns\n",
    "categorical_cols = data.select_dtypes(include = 'object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[numerical_cols] = num_imputer.fit_transform(data[numerical_cols])\n",
    "data[categorical_cols] = cat_imputer.fit_transform(data[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsfordummies = data.select_dtypes(include='object').drop(['Policy Start Date'], axis=1).columns\n",
    "data = pd.get_dummies(data,columns=colsfordummies, drop_first=True)\n",
    "bool_cols = data.select_dtypes(include='bool').columns\n",
    "data[bool_cols] = data[bool_cols].astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Policy Start Date'] = pd.to_datetime(data['Policy Start Date'])\n",
    "data['Policy Age'] = (pd.to_datetime('2025-01-01') - data['Policy Start Date']).dt.days\n",
    "data.drop(['Policy Start Date','id'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Premium Amount</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>...</th>\n",
       "      <th>Policy Type_Premium</th>\n",
       "      <th>Customer Feedback_Good</th>\n",
       "      <th>Customer Feedback_Poor</th>\n",
       "      <th>Smoking Status_Yes</th>\n",
       "      <th>Exercise Frequency_Monthly</th>\n",
       "      <th>Exercise Frequency_Rarely</th>\n",
       "      <th>Exercise Frequency_Weekly</th>\n",
       "      <th>Property Type_Condo</th>\n",
       "      <th>Property Type_House</th>\n",
       "      <th>Policy Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>549982</th>\n",
       "      <td>0.130142</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>-1.473089</td>\n",
       "      <td>-0.502390</td>\n",
       "      <td>-1.211843</td>\n",
       "      <td>1.102336</td>\n",
       "      <td>0.240305</td>\n",
       "      <td>0.752139</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661271</th>\n",
       "      <td>0.204007</td>\n",
       "      <td>1.525750</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-1.518146</td>\n",
       "      <td>1.200985</td>\n",
       "      <td>-0.962769</td>\n",
       "      <td>-0.971070</td>\n",
       "      <td>0.368042</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95378</th>\n",
       "      <td>-0.608505</td>\n",
       "      <td>-0.278691</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.878374</td>\n",
       "      <td>1.200985</td>\n",
       "      <td>0.241875</td>\n",
       "      <td>1.752773</td>\n",
       "      <td>1.520333</td>\n",
       "      <td>3138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109118</th>\n",
       "      <td>-0.386911</td>\n",
       "      <td>3.383639</td>\n",
       "      <td>-1.473089</td>\n",
       "      <td>-0.794018</td>\n",
       "      <td>-0.005429</td>\n",
       "      <td>-0.274401</td>\n",
       "      <td>-1.062098</td>\n",
       "      <td>0.368042</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205036</th>\n",
       "      <td>1.459708</td>\n",
       "      <td>1.207539</td>\n",
       "      <td>-0.733735</td>\n",
       "      <td>1.380249</td>\n",
       "      <td>-1.211843</td>\n",
       "      <td>-1.479046</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>-1.168347</td>\n",
       "      <td>264.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age  Annual Income  Number of Dependents  Health Score  \\\n",
       "549982  0.130142       0.010664             -1.473089     -0.502390   \n",
       "661271  0.204007       1.525750              0.005619     -1.518146   \n",
       "95378  -0.608505      -0.278691              0.005619      0.878374   \n",
       "109118 -0.386911       3.383639             -1.473089     -0.794018   \n",
       "205036  1.459708       1.207539             -0.733735      1.380249   \n",
       "\n",
       "        Previous Claims  Vehicle Age  Credit Score  Insurance Duration  \\\n",
       "549982        -1.211843     1.102336      0.240305            0.752139   \n",
       "661271         1.200985    -0.962769     -0.971070            0.368042   \n",
       "95378          1.200985     0.241875      1.752773            1.520333   \n",
       "109118        -0.005429    -0.274401     -1.062098            0.368042   \n",
       "205036        -1.211843    -1.479046      0.016235           -1.168347   \n",
       "\n",
       "        Premium Amount  Gender_Male  ...  Policy Type_Premium  \\\n",
       "549982            29.0          1.0  ...                  0.0   \n",
       "661271            40.0          0.0  ...                  0.0   \n",
       "95378           3138.0          0.0  ...                  0.0   \n",
       "109118          1513.0          1.0  ...                  0.0   \n",
       "205036           264.0          1.0  ...                  0.0   \n",
       "\n",
       "        Customer Feedback_Good  Customer Feedback_Poor  Smoking Status_Yes  \\\n",
       "549982                     0.0                     0.0                 0.0   \n",
       "661271                     1.0                     0.0                 1.0   \n",
       "95378                      0.0                     1.0                 0.0   \n",
       "109118                     0.0                     0.0                 0.0   \n",
       "205036                     0.0                     1.0                 1.0   \n",
       "\n",
       "        Exercise Frequency_Monthly  Exercise Frequency_Rarely  \\\n",
       "549982                         0.0                        0.0   \n",
       "661271                         0.0                        0.0   \n",
       "95378                          0.0                        0.0   \n",
       "109118                         1.0                        0.0   \n",
       "205036                         1.0                        0.0   \n",
       "\n",
       "        Exercise Frequency_Weekly  Property Type_Condo  Property Type_House  \\\n",
       "549982                        0.0                  1.0                  0.0   \n",
       "661271                        1.0                  0.0                  1.0   \n",
       "95378                         0.0                  0.0                  1.0   \n",
       "109118                        0.0                  1.0                  0.0   \n",
       "205036                        0.0                  0.0                  0.0   \n",
       "\n",
       "        Policy Age  \n",
       "549982         508  \n",
       "661271        1179  \n",
       "95378          987  \n",
       "109118         299  \n",
       "205036        1818  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Premium Amount'], axis=1)\n",
    "y = data['Premium Amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchNormalisation normalises the output from a given layer of neurons so that the weights that they learn tend to be on the same scale of things. Helps against overfitting and lets models train faster as they would need less no of epochs to train for the same accuracy as without the normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop out is for randomly zeroing the   scores learnt from a given neuraon with the input probablity so that there is less overfitting chances as the less dominant  neurons also get to get their weights trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionforInsurance(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearRegressionforInsurance, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),  # output size 1024\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(1024),  # BatchNorm with 1024\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),  # output size 512\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(512),  # BatchNorm with 512\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(512, 256),  # output size 256\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(256),  # BatchNorm with 256\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(256, 128),  # output size 128\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(128),  # BatchNorm with 128\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(128, 1)  # output size 1 (final prediction)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.layer1(X)\n",
    "        X = self.layer2(X)\n",
    "        X = self.layer3(X)\n",
    "        X = self.layer4(X)\n",
    "        return self.layer5(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "X_train_t = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train.to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_t = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test.to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "y_train_t = torch.log(y_train_t + 1)  \n",
    "y_test_t = torch.log(y_test_t + 1)\n",
    "\n",
    "\n",
    "#train_dataset = TensorDataset(X_train, y_train)\n",
    "#test_dataset = TensorDataset(X_test,y_test)\n",
    "\n",
    "#train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "torch.Size([3000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_test_t.shape[1])\n",
    "print(y_test_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = LinearRegressionforInsurance(X_train.shape[1])\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model0.parameters(), lr = 1e-3, weight_decay=1e-2)\n",
    "# weight decay is L2 regularization \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=125, gamma=0.5)\n",
    "# the scheduler changes the learning  rate mid training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.clip_grad import clip_grad_norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1,  TRAINLOSS: 45.1829 , TESTLOSS: 56.2716\n",
      "EPOCH : 26,  TRAINLOSS: 42.5894 , TESTLOSS: 42.3973\n",
      "EPOCH : 51,  TRAINLOSS: 38.0598 , TESTLOSS: 37.5154\n",
      "EPOCH : 76,  TRAINLOSS: 30.1734 , TESTLOSS: 29.7810\n",
      "EPOCH : 101,  TRAINLOSS: 20.2751 , TESTLOSS: 20.1164\n",
      "EPOCH : 126,  TRAINLOSS: 11.0875 , TESTLOSS: 10.8068\n",
      "EPOCH : 151,  TRAINLOSS: 7.7115 , TESTLOSS: 6.9103\n",
      "EPOCH : 176,  TRAINLOSS: 5.2461 , TESTLOSS: 4.8026\n",
      "EPOCH : 201,  TRAINLOSS: 3.6210 , TESTLOSS: 2.9622\n",
      "EPOCH : 226,  TRAINLOSS: 2.6521 , TESTLOSS: 2.0615\n",
      "EPOCH : 251,  TRAINLOSS: 2.1651 , TESTLOSS: 1.5738\n",
      "EPOCH : 276,  TRAINLOSS: 2.0167 , TESTLOSS: 1.4709\n",
      "EPOCH : 301,  TRAINLOSS: 1.8937 , TESTLOSS: 1.3589\n",
      "EPOCH : 326,  TRAINLOSS: 1.8463 , TESTLOSS: 1.2967\n",
      "EPOCH : 351,  TRAINLOSS: 1.8266 , TESTLOSS: 1.2652\n",
      "EPOCH : 376,  TRAINLOSS: 1.8145 , TESTLOSS: 1.2391\n",
      "EPOCH : 401,  TRAINLOSS: 1.7634 , TESTLOSS: 1.2324\n",
      "EPOCH : 426,  TRAINLOSS: 1.7212 , TESTLOSS: 1.2264\n",
      "EPOCH : 451,  TRAINLOSS: 1.7484 , TESTLOSS: 1.2224\n",
      "EPOCH : 476,  TRAINLOSS: 1.7718 , TESTLOSS: 1.2171\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "max_grad_norm = 1.0\n",
    "for epoch in range(epochs):\n",
    "    model0.train()\n",
    "    y_pred = model0(X_train_t)\n",
    "    loss = loss_function(y_pred, y_train_t)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    clip_grad_norm_(model0.parameters(), max_grad_norm)\n",
    "    with torch.no_grad():\n",
    "        model0.eval()\n",
    "        y_test_pred = model0(X_test_t)\n",
    "        test_loss = loss_function(y_test_pred, y_test_t)\n",
    "    if  epoch%25==0:\n",
    "        print(f'EPOCH : {epoch + 1},  TRAINLOSS: {loss.item():.4f} , TESTLOSS: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: -0.2708   | RMSLE: 1.1016    | RMSE: 976.0803   | MAE 678.5445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, root_mean_squared_log_error, root_mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_test_pred = model0(X_test_t)\n",
    "y_test_pred_actual = torch.exp(y_test_pred) - 1\n",
    "y_test_actual = torch.exp(y_test_t) - 1\n",
    "\n",
    "# Detach the tensors and convert them to NumPy arrays\n",
    "y_test_pred_actual = y_test_pred_actual.detach().numpy()\n",
    "y_test_actual = y_test_actual.detach().numpy()\n",
    "\n",
    "# During the evaluation phase:\n",
    "\n",
    "rmsle = root_mean_squared_log_error(y_test_actual, y_test_pred_actual)\n",
    "rmse = root_mean_squared_error(y_test_actual, y_test_pred_actual)\n",
    "mae = mean_absolute_error(y_test_actual, y_test_pred_actual)\n",
    "\n",
    "print(f' RMSLE: {rmsle:.4f}    | RMSE: {rmse:.4f}   | MAE {mae:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "y_Train_TT = np.log(y_train  + 1)\n",
    "y_Test_TT = np.log(y_test  + 1)\n",
    "boosting_reg = xgb.XGBRegressor()\n",
    "boosting_reg.fit(X_train, y_Train_TT)\n",
    "y_predXGB = boosting_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16963050893562365\n"
     ]
    }
   ],
   "source": [
    "y_test_NL = np.exp(y_Test_TT) - 1\n",
    "y_train_NL = np.exp(y_Train_TT) - 1 # NL IS FOR NON_LOG\n",
    "error_XGB = root_mean_squared_log_error(y_Test_TT, y_predXGB)\n",
    "print(error_XGB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
